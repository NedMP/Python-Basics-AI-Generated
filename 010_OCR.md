

# Python OCR Fundamentals — updated Oct 5, 2025

Beginner‑friendly overview of modern OCR (Optical Character Recognition) in Python. Covers local OCR with **Tesseract** and **pytesseract**, alternative engines (**EasyOCR**, **PaddleOCR**, **Transformers/trOCR**), cloud OCR (Google, AWS, Azure), image pre‑processing with Pillow/OpenCV, PDFs, layout detection, tables, and common pitfalls. Use with `002_SETUP.md` for environment setup.

---

**Assumptions and Conventions**
- macOS + zsh, Python 3.12+ or 3.13 in a venv.  
- Commands show input; output is shown without prompts.  
- Sample images are referred to as `samples/scan.png` and PDFs as `samples/doc.pdf`.

---

## Table of Contents
- [0) OCR choices in 2025: quick guidance](#0-ocr-choices-in-2025-quick-guidance)
- [1) Install Tesseract and pytesseract](#1-install-tesseract-and-pytesseract)
- [2) First OCR: images → text](#2-first-ocr-images--text)
- [3) Languages, page segmentation, and configs](#3-languages-page-segmentation-and-configs)
- [4) Bounding boxes, confidence, and TSV/HOCR](#4-bounding-boxes-confidence-and-tsvhocr)
- [5) Pre‑processing with Pillow/OpenCV](#5-pre-processing-with-pillowopencv)
- [6) PDFs: images, searchable PDFs, OCRmyPDF](#6-pdfs-images-searchable-pdfs-ocrmypdf)
- [7) Layout and tables](#7-layout-and-tables)
- [8) Alternatives: EasyOCR, PaddleOCR, trOCR](#8-alternatives-easyocr-paddleocr-trocr)
- [9) Cloud OCR: Google Vision, AWS Textract, Azure Read](#9-cloud-ocr-google-vision-aws-textract-azure-read)
- [10) Performance, accuracy, and tips](#10-performance-accuracy-and-tips)
- [11) Troubleshooting](#11-troubleshooting)
- [12) Recap](#12-recap)

---

## 0) OCR choices in 2025: quick guidance
**Local and free:**
- **Tesseract 5** with `pytesseract` for printed text in common languages. Good quality with the right pre‑processing. Fast on CPU.  
- **PaddleOCR / EasyOCR** for broader script coverage and better out‑of‑the‑box detection on noisy photos.

**Handwriting or complex layouts:**
- Try **Microsoft Azure Read**, **Google Cloud Vision (Document AI)**, or **AWS Textract**. Also consider **trOCR** (Transformers) for offline handwriting, but quality varies.

**PDF pipelines:**
- **OCRmyPDF** creates searchable PDFs and manages page rotation, deskew, language packs, and page‑wise OCR.

---

## 1) Install Tesseract and pytesseract
**What**: Install the OCR engine and Python bindings.  
**Why**: Tesseract is the de facto open‑source baseline.
```sh
brew install tesseract  # installs engine and English data
brew info tesseract     # shows data directory and available languages
# Optional language packs (examples):
brew install tesseract-lang
```
Python package:
```sh
pip install pytesseract pillow opencv-python
```
Verify versions:
```sh
tesseract --version
python - <<'PY'
import pytesseract, PIL, cv2
print('pytesseract', pytesseract.get_tesseract_version())
PY
```
If Homebrew is not on PATH, export `TESSDATA_PREFIX` to the language data folder (`$(brew --prefix)/Cellar/tesseract/.../share/tessdata`).

---

## 2) First OCR: images → text
**What**: Extract plain text from a PNG/JPG.  
**Why**: Baseline check.
```python
from PIL import Image
import pytesseract

img = Image.open("samples/scan.png")
text = pytesseract.image_to_string(img)
print(text)
```
> Expected: a text dump. Quality depends on resolution, contrast, and languages.

---

## 3) Languages, page segmentation, and configs
**What**: Improve accuracy with the right language model and layout hints.  
**Why**: Tesseract accuracy depends on configuration.
```python
from PIL import Image
import pytesseract

img = Image.open("samples/scan.png")
# English + Australian English as example; adjust to your needs
text = pytesseract.image_to_string(
    img,
    lang="eng",  # add +deu +fra etc. if installed
    config="--psm 6"  # 6 = Assume a uniform block of text
)
print(text)
```
Common `--psm` modes:
- `3` fully automatic (default).  
- `6` single uniform block.  
- `7` single text line.  
- `8` single word.  
- `11` sparse text.

Other useful flags: `-c tessedit_char_blacklist=`, `-c preserve_interword_spaces=1`.

---

## 4) Bounding boxes, confidence, and TSV/HOCR
**What**: Extract positions and confidence for words or lines.  
**Why**: Needed for highlighting, redaction, or structured extraction.
```python
import pytesseract
from PIL import Image

img = Image.open("samples/scan.png")

# TSV (tab‑separated) result with bounding boxes
tsv = pytesseract.image_to_data(img, lang="eng", config="--psm 6")
print(tsv.splitlines()[0])  # header: level, page_num, block_num, ...

# HOCR HTML (coordinates in title attributes)
hocr = pytesseract.image_to_pdf_or_hocr(img, extension='hocr')
with open('out.hocr', 'wb') as f: f.write(hocr)

# Searchable PDF (image over text)
pdf_bytes = pytesseract.image_to_pdf_or_hocr(img, extension='pdf')
with open('out.pdf', 'wb') as f: f.write(pdf_bytes)
```
TSV columns include `left,top,width,height,conf,text`. Filter low confidence rows and empty strings.

---

## 5) Pre‑processing with Pillow/OpenCV
**What**: Clean the image for better OCR.  
**Why**: Pre‑processing often yields bigger gains than switching engines.
```python
import cv2
import numpy as np
from PIL import Image
import pytesseract

img = cv2.imread('samples/scan.png')
# 1) Grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# 2) Binarize (adaptive or Otsu)
th = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]
# 3) Deskew using moments
coords = np.column_stack(np.where(th > 0))
angle = cv2.minAreaRect(coords)[-1]
angle = -(90 + angle) if angle < -45 else -angle
(h, w) = th.shape[:2]
M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
rot = cv2.warpAffine(th, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
# 4) Resize up for small text
scale = 2.0
resized = cv2.resize(rot, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)

text = pytesseract.image_to_string(Image.fromarray(resized), lang='eng', config='--psm 6')
print(text)
```
Other tricks: **denoise** (`medianBlur`), **morphology** to close gaps, and **invert** if white‑on‑black.

---

## 6) PDFs: images, searchable PDFs, OCRmyPDF
**What**: Handle multi‑page PDFs and produce searchable results.  
**Why**: Many scans ship as PDFs, not images.
```sh
pip install pypdf pdf2image ocrmypdf
brew install poppler  # provides pdftoppm/pdfimages for rasterization
```
Extract images/pages for OCR:
```python
from pdf2image import convert_from_path
pages = convert_from_path('samples/doc.pdf', dpi=300)
for i, page in enumerate(pages, 1):
    page.save(f'page_{i}.png', 'PNG')
```
Make a searchable PDF directly:
```sh
ocrmypdf --language eng --output-type pdf --rotate-pages --deskew samples/doc.pdf out_searchable.pdf
```
`ocrmypdf` orchestrates Tesseract per page and embeds a hidden text layer.

---

## 7) Layout and tables
**What**: Detect headings, paragraphs, and tables for structured extraction.  
**Why**: Plain text loses structure.
- **layoutparser** (deep learning‑based layout detection)  
- **detectron2** models for document zones  
- **camelot** or **pdfplumber** for PDF tables (vector/PDF‑native), else **ocr‑table** heuristics for image tables

Example table extraction from PDF (not scans):
```sh
pip install camelot-py[cv] pdfplumber
```
```python
import camelot
# Works on PDFs with vector lines; needs Ghostscript on macOS (brew install ghostscript)
# camelot.read_pdf returns table objects you can export to CSV
```
For scanned tables, detect grid lines with OpenCV, then pass cell crops through OCR.

---

## 8) Alternatives: EasyOCR, PaddleOCR, trOCR
**EasyOCR**
```sh
pip install easyocr
```
```python
import easyocr
reader = easyocr.Reader(['en'])  # downloads model on first run
result = reader.readtext('samples/scan.png')
print(result)  # list of (bbox, text, confidence)
```
**PaddleOCR**
```sh
pip install "paddleocr>=2.7" paddlepaddle  # choose paddlepaddle‑cpu or paddlepaddle‑macos depending on platform
```
```python
from paddleocr import PaddleOCR
ocr = PaddleOCR(lang='en')
res = ocr.ocr('samples/scan.png', det=True, rec=True)
for line in res[0]:
    bbox, (txt, conf) = line
    print(conf, txt)
```
**trOCR (Transformers)** — offline handwriting recognition (quality varies with model and language):
```sh
pip install torch torchvision torchaudio transformers pillow
```
```python
from transformers import TrOCRProcessor, VisionEncoderDecoderModel
from PIL import Image

processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")

image = Image.open("samples/handwriting.png").convert("RGB")
inputs = processor(images=image, return_tensors="pt")
out = model.generate(**inputs)
print(processor.batch_decode(out, skip_special_tokens=True)[0])
```

---

## 9) Cloud OCR: Google Vision, AWS Textract, Azure Read
**Why cloud**: Better accuracy on handwriting, forms, and complex layouts. Adds structure (blocks, lines, tables, key‑value pairs). Costs money and needs credentials.

- **Google Cloud Vision / Document AI**: general OCR + form parsers.  
- **AWS Textract**: text, tables, and key‑value pairs from forms.  
- **Azure AI Vision Read**: high accuracy on multi‑language and handwriting.

Patterns are similar: send image/PDF bytes or cloud storage URIs, get JSON back with text blocks and geometry. Use SDKs, not raw HTTP.

Example (pseudocode shape only):
```python
# Install provider SDK, set credentials via env vars or config files.
# Example with Azure AI Vision Read:
# pip install azure-ai-formrecognizer
from azure.ai.formrecognizer import DocumentAnalysisClient
from azure.core.credentials import AzureKeyCredential

client = DocumentAnalysisClient(endpoint=ENDPOINT, credential=AzureKeyCredential(KEY))
with open('samples/doc.pdf', 'rb') as f:
    poller = client.begin_analyze_document(model_id="prebuilt-read", document=f)
result = poller.result()
for page in result.pages:
    for line in page.lines:
        print(line.content)
```

---

## 10) Performance, accuracy, and tips
- **DPI**: Aim for 300 DPI scans. Low‑res photos hurt accuracy.  
- **Contrast**: Increase contrast, binarize, and denoise.  
- **Rotation/deskew**: Fix skew before OCR; `ocrmypdf` can auto‑rotate.  
- **Language packs**: Install the correct `tessdata` languages and set `lang="eng+deu"` etc.  
- **Page segmentation**: Choose the right `--psm` for the layout.  
- **Confidence filtering**: Drop words below a threshold (e.g., `< 60`).  
- **Batching**: Reuse models and processes. Don’t re‑load on every page.  
- **Security**: Never send sensitive docs to cloud OCR without approval.  
- **Reproducibility**: Pin versions in `requirements.txt` and record engine versions.

---

## 11) Troubleshooting
- **`pytesseract.pytesseract.TesseractNotFoundError`**: Tesseract not installed or not on PATH. Point `pytesseract.pytesseract.tesseract_cmd` to the binary.  
- **Garbled output**: wrong language model, low DPI, poor binarization, or wrong `--psm`.  
- **No text detected**: image is inverted, rotated, or is a photo with background clutter. Pre‑process.  
- **PDF errors**: install Poppler; or use `ocrmypdf` to handle page rasterization.  
- **Handwriting poor**: try cloud engines or trOCR.  
- **Performance**: vectorize pre‑processing with OpenCV, use multiprocessing for page batches.

---

## 12) Recap
```plaintext
Pick engine → Install (Tesseract/EasyOCR/PaddleOCR) → Pre‑process images → OCR with proper lang+psm → Parse boxes/TSV → For PDFs use OCRmyPDF → Use cloud OCR for handwriting/complex docs
```

**Next**: Add persistence (SQLite/CSV), structured logging, and a small CLI (`argparse`) to batch‑OCR folders and generate searchable PDFs and TSV summaries.